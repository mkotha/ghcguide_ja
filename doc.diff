diff -urd 7.2.2-original/profiling.xml original/profiling.xml
--- 7.2.2-original/profiling.xml	2011-11-10 02:10:39.000000000 +0800
+++ original/profiling.xml	2012-02-02 02:10:32.000000000 +0800
@@ -5,45 +5,52 @@
   </indexterm>
   <indexterm><primary>cost-centre profiling</primary></indexterm>
 
-  <para> Glasgow Haskell comes with a time and space profiling
-  system. Its purpose is to help you improve your understanding of
-  your program's execution behaviour, so you can improve it.</para>
-
-  <para> Any comments, suggestions and/or improvements you have are
-  welcome.  Recommended &ldquo;profiling tricks&rdquo; would be
-  especially cool! </para>
+  <para>GHC comes with a time and space profiling system, so that you
+  can answer questions like "why is my program so slow?", or "why is
+  my program using so much memory?".</para>
 
   <para>Profiling a program is a three-step process:</para>
 
   <orderedlist>
     <listitem>
-      <para> Re-compile your program for profiling with the
-      <literal>-prof</literal> option, and probably one of the
-      <literal>-auto</literal> or <literal>-auto-all</literal>
-      options.  These options are described in more detail in <xref
-      linkend="prof-compiler-options"/> </para>
-      <indexterm><primary><literal>-prof</literal></primary>
-      </indexterm>
-      <indexterm><primary><literal>-auto</literal></primary>
-      </indexterm>
-      <indexterm><primary><literal>-auto-all</literal></primary>
-      </indexterm>
+      <para>Re-compile your program for profiling with the
+      <literal>-prof</literal> option, and probably one of the options
+      for adding automatic annotations:
+      <literal>-fprof-auto</literal> is the most common<footnote><para><option>-fprof-auto</option> was known as <option>-auto-all</option><indexterm><primary><literal>-auto-all</literal></primary>
+      </indexterm> prior to GHC 7.4.1.</para></footnote>.
+      <indexterm><primary><literal>-fprof-auto</literal></primary>
+      </indexterm></para>
+
+      <para>If you are using external packages with
+      <literal>cabal</literal>, you may need to reinstall these
+      packages with profiling support; typically this is done with
+      <literal>cabal install -p <replaceable>package</replaceable>
+      --reinstall</literal>.</para>
     </listitem>
 
     <listitem>
-      <para> Run your program with one of the profiling options, eg.
-      <literal>+RTS -p -RTS</literal>.  This generates a file of
-      profiling information.  Note that multi-processor execution
-      (e.g. <literal>+RTS -N2</literal>) is not supported while
-      profiling.</para>
-      <indexterm><primary><option>-p</option></primary><secondary>RTS
-      option</secondary></indexterm>
+      <para>Having compiled the program for profiling, you now need to
+      run it to generate the profile.  For example, a simple time
+      profile can be generated by running the program with
+      <option>+RTS
+      -p</option><indexterm><primary><option>-p</option></primary><secondary>RTS
+      option</secondary></indexterm>, which generates a file named
+      <literal><replaceable>prog</replaceable>.prof</literal> where
+      <replaceable>prog</replaceable> is the name of your program
+      (without the <literal>.exe</literal> extension, if you are on
+      Windows).</para>
+
+      <para>There are many different kinds of profile that can be
+      generated, selected by different RTS options.  We will be
+      describing the various kinds of profile throughout the rest of
+      this chapter.  Some profiles require further processing using
+      additional tools after running the program.</para>
     </listitem>
 
     <listitem>
-      <para> Examine the generated profiling information, using one of
-      GHC's profiling tools.  The tool to use will depend on the kind
-      of profiling information generated.</para>
+      <para>Examine the generated profiling information, use the
+      information to optimise your program, and repeat as
+      necessary.</para>
     </listitem>
 
   </orderedlist>
@@ -53,24 +60,24 @@
 
     <para>GHC's profiling system assigns <firstterm>costs</firstterm>
     to <firstterm>cost centres</firstterm>.  A cost is simply the time
-    or space required to evaluate an expression.  Cost centres are
+    or space (memory) required to evaluate an expression.  Cost centres are
     program annotations around expressions; all costs incurred by the
     annotated expression are assigned to the enclosing cost centre.
     Furthermore, GHC will remember the stack of enclosing cost centres
-    for any given expression at run-time and generate a call-graph of
+    for any given expression at run-time and generate a call-tree of
     cost attributions.</para>
 
     <para>Let's take a look at an example:</para>
 
     <programlisting>
-main = print (nfib 25)
-nfib n = if n &lt; 2 then 1 else nfib (n-1) + nfib (n-2)
+main = print (fib 30)
+fib n = if n &lt; 2 then 1 else fib (n-1) + fib (n-2)
 </programlisting>
 
     <para>Compile and run this program as follows:</para>
 
     <screen>
-$ ghc -prof -auto-all -o Main Main.hs
+$ ghc -prof -fprof-auto -rtsopts Main.hs
 $ ./Main +RTS -p
 121393
 $
@@ -78,53 +85,52 @@
 
     <para>When a GHC-compiled program is run with the
     <option>-p</option> RTS option, it generates a file called
-    <filename>&lt;prog&gt;.prof</filename>.  In this case, the file
+    <filename><replaceable>prog</replaceable>.prof</filename>.  In this case, the file
     will contain something like this:</para>
 
 <screen>
-          Fri May 12 14:06 2000 Time and Allocation Profiling Report  (Final)
+        Wed Oct 12 16:14 2011 Time and Allocation Profiling Report  (Final)
 
            Main +RTS -p -RTS
 
-        total time  =        0.14 secs   (7 ticks @ 20 ms)
-        total alloc =   8,741,204 bytes  (excludes profiling overheads)
+        total time  =        0.68 secs   (34 ticks @ 20 ms)
+        total alloc = 204,677,844 bytes  (excludes profiling overheads)
 
-COST CENTRE          MODULE     %time %alloc
+COST CENTRE MODULE  %time %alloc
 
-nfib                 Main       100.0  100.0
+fib         Main    100.0  100.0
 
 
-                                              individual     inherited
-COST CENTRE              MODULE      entries %time %alloc   %time %alloc
+                                                      individual     inherited
+COST CENTRE MODULE                  no.     entries  %time %alloc   %time %alloc
 
-MAIN                     MAIN             0    0.0   0.0    100.0 100.0
- main                    Main             0    0.0   0.0      0.0   0.0
- CAF                     PrelHandle       3    0.0   0.0      0.0   0.0
- CAF                     PrelAddr         1    0.0   0.0      0.0   0.0
- CAF                     Main             6    0.0   0.0    100.0 100.0
-  main                   Main             1    0.0   0.0    100.0 100.0
-   nfib                  Main        242785  100.0 100.0    100.0 100.0
+MAIN        MAIN                    102           0    0.0    0.0   100.0  100.0
+ CAF        GHC.IO.Handle.FD        128           0    0.0    0.0     0.0    0.0
+ CAF        GHC.IO.Encoding.Iconv   120           0    0.0    0.0     0.0    0.0
+ CAF        GHC.Conc.Signal         110           0    0.0    0.0     0.0    0.0
+ CAF        Main                    108           0    0.0    0.0   100.0  100.0
+  main      Main                    204           1    0.0    0.0   100.0  100.0
+   fib      Main                    205     2692537  100.0  100.0   100.0  100.0
 </screen>
 
-
     <para>The first part of the file gives the program name and
     options, and the total time and total memory allocation measured
     during the run of the program (note that the total memory
     allocation figure isn't the same as the amount of
     <emphasis>live</emphasis> memory needed by the program at any one
     time; the latter can be determined using heap profiling, which we
-    will describe shortly).</para>
+    will describe later in <xref linkend="prof-heap" />).</para>
 
     <para>The second part of the file is a break-down by cost centre
     of the most costly functions in the program.  In this case, there
     was only one significant function in the program, namely
-    <function>nfib</function>, and it was responsible for 100&percnt;
+    <function>fib</function>, and it was responsible for 100&percnt;
     of both the time and allocation costs of the program.</para>
 
     <para>The third and final section of the file gives a profile
-    break-down by cost-centre stack.  This is roughly a call-graph
+    break-down by cost-centre stack.  This is roughly a call-tree
     profile of the program.  In the example above, it is clear that
-    the costly call to <function>nfib</function> came from
+    the costly call to <function>fib</function> came from
     <function>main</function>.</para>
 
     <para>The time and allocation incurred by a given part of the
@@ -137,33 +143,39 @@
     by  modifying the example slightly:</para>
 
     <programlisting>
-main = print (f 25 + g 25)
-f n  = nfib n
-g n  = nfib (n `div` 2)
-nfib n = if n &lt; 2 then 1 else nfib (n-1) + nfib (n-2)
+main = print (f 30 + g 30)
+  where
+    f n  = fib n
+    g n  = fib (n `div` 2)
+
+fib n = if n &lt; 2 then 1 else fib (n-1) + fib (n-2)
 </programlisting>
 
     <para>Compile and run this program as before, and take a look at
     the new profiling results:</para>
 
 <screen>
-COST CENTRE              MODULE         scc  %time %alloc   %time %alloc
+COST CENTRE MODULE                  no.     entries  %time %alloc   %time %alloc
 
-MAIN                     MAIN             0    0.0   0.0    100.0 100.0
- main                    Main             0    0.0   0.0      0.0   0.0
- CAF                     PrelHandle       3    0.0   0.0      0.0   0.0
- CAF                     PrelAddr         1    0.0   0.0      0.0   0.0
- CAF                     Main             9    0.0   0.0    100.0 100.0
-  main                   Main             1    0.0   0.0    100.0 100.0
-   g                     Main             1    0.0   0.0      0.0   0.2
-    nfib                 Main           465    0.0   0.2      0.0   0.2
-   f                     Main             1    0.0   0.0    100.0  99.8
-    nfib                 Main        242785  100.0  99.8    100.0  99.8
+MAIN        MAIN                    102           0    0.0    0.0   100.0  100.0
+ CAF        GHC.IO.Handle.FD        128           0    0.0    0.0     0.0    0.0
+ CAF        GHC.IO.Encoding.Iconv   120           0    0.0    0.0     0.0    0.0
+ CAF        GHC.Conc.Signal         110           0    0.0    0.0     0.0    0.0
+ CAF        Main                    108           0    0.0    0.0   100.0  100.0
+  main      Main                    204           1    0.0    0.0   100.0  100.0
+   main.g   Main                    207           1    0.0    0.0     0.0    0.1
+    fib     Main                    208        1973    0.0    0.1     0.0    0.1
+   main.f   Main                    205           1    0.0    0.0   100.0   99.9
+    fib     Main                    206     2692537  100.0   99.9   100.0   99.9
 </screen>
 
-    <para>Now although we had two calls to <function>nfib</function>
-    in the program, it is immediately clear that it was the call from
-    <function>f</function> which took all the time.</para>
+    <para>Now although we had two calls to <function>fib</function> in
+    the program, it is immediately clear that it was the call from
+    <function>f</function> which took all the time.  The functions
+    <literal>f</literal> and <literal>g</literal> which are defined in
+    the <literal>where</literal> clause in <literal>main</literal> are
+    given their own cost centres, <literal>main.f</literal> and
+    <literal>main.g</literal> respectively.</para>
 
     <para>The actual meaning of the various columns in the output is:</para>
 
@@ -172,7 +184,7 @@
 	<term>entries</term>
 	<listitem>
 	  <para>The number of times this particular point in the call
-	  graph was entered.</para>
+	  tree was entered.</para>
 	</listitem>
       </varlistentry>
 
@@ -180,7 +192,7 @@
 	<term>individual &percnt;time</term>
 	<listitem>
 	  <para>The percentage of the total run time of the program
-	  spent at this point in the call graph.</para>
+	  spent at this point in the call tree.</para>
 	</listitem>
       </varlistentry>
 
@@ -197,7 +209,7 @@
 	<term>inherited &percnt;time</term>
 	<listitem>
 	  <para>The percentage of the total run time of the program
-	  spent below this point in the call graph.</para>
+	  spent below this point in the call tree.</para>
 	</listitem>
       </varlistentry>
 
@@ -242,19 +254,24 @@
     although GHC does keep information about which groups of functions
     called each other recursively, this information isn't displayed in
     the basic time and allocation profile, instead the call-graph is
-    flattened into a tree.</para>
+    flattened into a tree as follows: a call to a function that occurs
+    elsewhere on the current stack does not push another entry on the
+    stack, instead the costs for this call are aggregated into the
+    caller<footnote><para>Note that this policy has changed slightly
+    in GHC 7.4.1 relative to earlier versions, and may yet change
+    further, feedback is welcome.</para></footnote>.</para>
 
-    <sect2><title>Inserting cost centres by hand</title>
+    <sect2 id="scc-pragma"><title>Inserting cost centres by hand</title>
 
       <para>Cost centres are just program annotations.  When you say
-      <option>-auto-all</option> to the compiler, it automatically
-      inserts a cost centre annotation around every top-level function
-      not marked INLINE in your program, but you are entirely free to
-      add the cost centre annotations yourself.</para>
+      <option>-fprof-auto</option> to the compiler, it automatically
+      inserts a cost centre annotation around every binding not marked
+      INLINE in your program, but you are entirely free to add cost
+      centre annotations yourself.</para>
 
       <para>The syntax of a cost centre annotation is</para>
 
-      <programlisting>
+<programlisting>
      {-# SCC "name" #-} &lt;expression&gt;
 </programlisting>
 
@@ -264,98 +281,83 @@
       <literal>&lt;expression&gt;</literal> is any Haskell
       expression.  An <literal>SCC</literal> annotation extends as
       far to the right as possible when parsing. (SCC stands for "Set
-      Cost Centre").</para>
+      Cost Centre").  The double quotes can be omitted
+      if <literal>name</literal> is a Haskell identifier, for example:</para>
+
+<programlisting>
+     {-# SCC my_function #-} &lt;expression&gt;
+</programlisting>
 
       <para>Here is an example of a program with a couple of SCCs:</para>
 
 <programlisting>
 main :: IO ()
-main = do let xs = {-# SCC "X" #-} [1..1000000]
-          let ys = {-# SCC "Y" #-} [1..2000000]
-          print $ last xs
-          print $ last $ init xs
-          print $ last ys
-          print $ last $ init ys
+main = do let xs = [1..1000000]
+          let ys = [1..2000000]
+          print $ {-# SCC last_xs #-} last xs
+          print $ {-# SCC last_init_xs #-} last $ init xs
+          print $ {-# SCC last_ys #-} last ys
+          print $ {-# SCC last_init_ys #-}last $ init ys
 </programlisting>
 
-      <para>which gives this heap profile when run:</para>
+      <para>which gives this profile when run:</para>
 
-      <!-- contentwidth/contentheight don't appear to have any effect
-           other than making the PS file generation work, rather than
-           falling over.  The result seems to be broken PS on the page
-           with the image. -->
-      <imagedata fileref="prof_scc" contentwidth="645px"
-      contentdepth="428px"/>
+<screen>
+COST CENTRE     MODULE                  no.     entries  %time %alloc   %time %alloc
+
+MAIN            MAIN                    102           0    0.0    0.0   100.0  100.0
+ CAF            GHC.IO.Handle.FD        130           0    0.0    0.0     0.0    0.0
+ CAF            GHC.IO.Encoding.Iconv   122           0    0.0    0.0     0.0    0.0
+ CAF            GHC.Conc.Signal         111           0    0.0    0.0     0.0    0.0
+ CAF            Main                    108           0    0.0    0.0   100.0  100.0
+  main          Main                    204           1    0.0    0.0   100.0  100.0
+   last_init_ys Main                    210           1   25.0   27.4    25.0   27.4
+   main.ys      Main                    209           1   25.0   39.2    25.0   39.2
+   last_ys      Main                    208           1   12.5    0.0    12.5    0.0
+   last_init_xs Main                    207           1   12.5   13.7    12.5   13.7
+   main.xs      Main                    206           1   18.8   19.6    18.8   19.6
+   last_xs      Main                    205           1    6.2    0.0     6.2    0.0
+</screen>
 
     </sect2>
 
     <sect2 id="prof-rules">
       <title>Rules for attributing costs</title>
 
-      <para>The cost of evaluating any expression in your program is
-      attributed to a cost-centre stack using the following rules:</para>
-
-      <itemizedlist>
-	<listitem>
-	  <para>If the expression is part of the
-	  <firstterm>one-off</firstterm> costs of evaluating the
-	  enclosing top-level definition, then costs are attributed to
-	  the stack of lexically enclosing <literal>SCC</literal>
-	  annotations on top of the special <literal>CAF</literal>
-	  cost-centre. </para>
-	</listitem>
-
-	<listitem>
-	  <para>Otherwise, costs are attributed to the stack of
-	  lexically-enclosing <literal>SCC</literal> annotations,
-	  appended to the cost-centre stack in effect at the
-	  <firstterm>call site</firstterm> of the current top-level
-	  definition<footnote> <para>The call-site is just the place
-	  in the source code which mentions the particular function or
-	  variable.</para></footnote>.  Notice that this is a recursive
-	  definition.</para>
-	</listitem>
-
-	<listitem>
-	  <para>Time spent in foreign code (see <xref linkend="ffi"/>)
-	  is always attributed to the cost centre in force at the
-	  Haskell call-site of the foreign function.</para>
-	</listitem>
-      </itemizedlist>
-
-      <para>What do we mean by one-off costs?  Well, Haskell is a lazy
-      language, and certain expressions are only ever evaluated once.
-      For example, if we write:</para>
-
-      <programlisting>
-x = nfib 25
-</programlisting>
-
-      <para>then <varname>x</varname> will only be evaluated once (if
-      at all), and subsequent demands for <varname>x</varname> will
-      immediately get to see the cached result.  The definition
-      <varname>x</varname> is called a CAF (Constant Applicative
-      Form), because it has no arguments.</para>
-
-      <para>For the purposes of profiling, we say that the expression
-      <literal>nfib 25</literal> belongs to the one-off costs of
-      evaluating <varname>x</varname>.</para>
+      <para>While running a program with profiling turned on, GHC
+      maintains a cost-centre stack behind the scenes, and attributes
+      any costs (memory allocation and time) to whatever the current
+      cost-centre stack is at the time the cost is incurred.</para>
 
-      <para>Since one-off costs aren't strictly speaking part of the
-      call-graph of the program, they are attributed to a special
-      top-level cost centre, <literal>CAF</literal>.  There may be one
-      <literal>CAF</literal> cost centre for each module (the
-      default), or one for each top-level definition with any one-off
-      costs (this behaviour can be selected by giving GHC the
-      <option>-caf-all</option> flag).</para>
+      <para>The mechanism is simple: whenever the program evaluates an
+      expression with an SCC annotation, <literal>{-# SCC c -#}
+      E</literal>, the cost centre <literal>c</literal> is pushed on
+      the current stack, and the entry count for this stack is
+      incremented by one.  The stack also sometimes has to be saved
+      and restored; in particular when the program creates a
+      <firstterm>thunk</firstterm> (a lazy suspension), the current
+      cost-centre stack is stored in the thunk, and restored when the
+      thunk is evaluated.  In this way, the cost-centre stack is
+      independent of the actual evaluation order used by GHC at
+      runtime.</para>
 
-      <indexterm><primary><literal>-caf-all</literal></primary>
-      </indexterm>
+      <para>At a function call, GHC takes the stack stored in the
+      function being called (which for a top-level function will be
+      empty), and <emphasis>appends</emphasis> it to the current
+      stack, ignoring any prefix that is identical to a prefix of the
+      current stack.</para>
 
-      <para>If you think you have a weird profile, or the call-graph
-      doesn't look like you expect it to, feel free to send it (and
-      your program) to us at
-      <email>glasgow-haskell-bugs@haskell.org</email>.</para>
+      <para>We mentioned earlier that lazy computations, i.e. thunks,
+      capture the current stack when they are created, and restore
+      this stack when they are evaluated.  What about top-level
+      thunks?  They are "created" when the program is compiled, so
+      what stack should we give them?  The technical name for a
+      top-level thunk is a CAF ("Constant Applicative Form").  GHC
+      assigns every CAF in a module a stack consisting of the single
+      cost centre <literal>M.CAF</literal>, where <literal>M</literal>
+      is the name of the module.  It is also possible to give each CAF
+      a different stack, using the option
+      <option>-fprof-cafs</option><indexterm><primary><option>-fprof-cafs</option></primary></indexterm>.</para>
     </sect2>
   </sect1>
 
@@ -372,13 +374,13 @@
           <indexterm><primary><option>-prof</option></primary></indexterm>
         </term>
 	<listitem>
-	  <para> To make use of the profiling system
+	  <para>To make use of the profiling system
           <emphasis>all</emphasis> modules must be compiled and linked
           with the <option>-prof</option> option. Any
           <literal>SCC</literal> annotations you've put in your source
           will spring to life.</para>
 
-	  <para> Without a <option>-prof</option> option, your
+	  <para>Without a <option>-prof</option> option, your
           <literal>SCC</literal>s are ignored; so you can compile
           <literal>SCC</literal>-laden code without changing
           it.</para>
@@ -394,40 +396,70 @@
     <variablelist>
       <varlistentry>
 	<term>
-          <option>-auto</option>:
-          <indexterm><primary><option>-auto</option></primary></indexterm>
+          <option>-fprof-auto</option>:
+          <indexterm><primary><option>-fprof-auto</option></primary></indexterm>
+        </term>
+	<listitem>
+          <para><emphasis>All</emphasis> bindings not marked INLINE,
+          whether exported or not, top level or nested, will be given
+          automatic <literal>SCC</literal> annotations.  Functions
+          marked INLINE must be given a cost centre manually.</para>
+	</listitem>
+      </varlistentry>
+
+      <varlistentry>
+	<term>
+          <option>-fprof-auto-top</option>:
+          <indexterm><primary><option>-fprof-auto-top</option></primary></indexterm>
           <indexterm><primary>cost centres</primary><secondary>automatically inserting</secondary></indexterm>
         </term>
 	<listitem>
-	  <para> GHC will automatically add
-          <function>&lowbar;scc&lowbar;</function> constructs for all
-          top-level, exported functions not marked INLINE. If you
-          want a cost centre on an INLINE function, you have to add
-          it manually.</para>
+	  <para>GHC will automatically add <literal>SCC</literal>
+	  annotations for all top-level bindings not marked INLINE. If
+	  you want a cost centre on an INLINE function, you have to
+	  add it manually.</para>
 	</listitem>
       </varlistentry>
 
       <varlistentry>
 	<term>
-          <option>-auto-all</option>:
-          <indexterm><primary><option>-auto-all</option></primary></indexterm>
+          <option>-fprof-auto-exported</option>:
+          <indexterm><primary><option>-fprof-auto-top</option></primary></indexterm>
+          <indexterm><primary>cost centres</primary><secondary>automatically inserting</secondary></indexterm>
         </term>
 	<listitem>
-          <para> <emphasis>All</emphasis> top-level functions
-          not marked INLINE, exported or not, will be automatically
-          <function>&lowbar;scc&lowbar;</function>'d.
-          The functions marked INLINE must be given a cost centre
-          manually.</para>
+	  <para>GHC will automatically add <literal>SCC</literal>
+          annotations for all exported functions not marked
+	  INLINE. If you want a cost centre on an INLINE function, you
+	  have to add it manually.</para>
 	</listitem>
       </varlistentry>
 
       <varlistentry>
 	<term>
-          <option>-caf-all</option>:
-          <indexterm><primary><option>-caf-all</option></primary></indexterm>
+          <option>-fprof-auto-calls</option>:
+          <indexterm><primary><option>-fprof-auto-calls</option></primary></indexterm>
         </term>
 	<listitem>
-	  <para> The costs of all CAFs in a module are usually
+          <para>Adds an automatic <literal>SCC</literal> annotation to
+            all <emphasis>call sites</emphasis>.  This is particularly
+            useful when using profiling for the purposes of generating
+            stack traces; see the
+            function <literal>traceStack</literal> in the
+            module <literal>Debug.Trace</literal>, or
+            the <literal>-xc</literal> RTS flag
+            (<xref linkend="rts-options-debugging" />) for more
+            details.</para>
+	</listitem>
+      </varlistentry>
+
+      <varlistentry>
+	<term>
+          <option>-fprof-cafs</option>:
+          <indexterm><primary><option>-fprof-cafs</option></primary></indexterm>
+        </term>
+	<listitem>
+	  <para>The costs of all CAFs in a module are usually
 	  attributed to one &ldquo;big&rdquo; CAF cost-centre. With
 	  this option, all CAFs get their own cost-centre.  An
 	  &ldquo;if all else fails&rdquo; option&hellip;</para>
@@ -436,17 +468,46 @@
 
       <varlistentry>
 	<term>
-          <option>-ignore-scc</option>:
-          <indexterm><primary><option>-ignore-scc</option></primary></indexterm>
+          <option>-fno-prof-auto</option>:
+          <indexterm><primary><option>-no-fprof-auto</option></primary></indexterm>
         </term>
 	<listitem>
-	  <para>Ignore any <function>&lowbar;scc&lowbar;</function>
-          constructs, so a module which already has
-          <function>&lowbar;scc&lowbar;</function>s can be compiled
-          for profiling with the annotations ignored.</para>
-	</listitem>
+          <para>Disables any previous <option>-fprof-auto</option>,
+          <option>-fprof-auto-top</option>, or
+          <option>-fprof-auto-exported</option> options.
+          </para>
+        </listitem>
+      </varlistentry>
+
+      <varlistentry>
+	<term>
+          <option>-fno-prof-cafs</option>:
+          <indexterm><primary><option>-fno-prof-cafs</option></primary></indexterm>
+        </term>
+	<listitem>
+          <para>Disables any previous <option>-fprof-cafs</option> option.
+          </para>
+        </listitem>
       </varlistentry>
 
+      <varlistentry>
+	<term>
+          <option>-fno-prof-count-entries</option>:
+          <indexterm><primary><option>-fno-prof-count-entries</option></primary></indexterm>
+        </term>
+	<listitem>
+          <para>Tells GHC not to collect information about how often
+          functions are entered at runtime (the "entries" column of
+          the time profile), for this module.  This tends to make the
+          profiled code run faster, and hence closer to the speed of
+          the unprofiled code, because GHC is able to optimise more
+          aggressively if it doesn't have to maintain correct entry
+          counts.  This option can be useful if you aren't interested
+          in the entry counts (for example, if you only intend to do
+          heap profiling).
+          </para>
+        </listitem>
+      </varlistentry>
     </variablelist>
 
   </sect1>
@@ -491,7 +552,7 @@
        <listitem>
          <para>Sets the interval that the RTS clock ticks at, which is
          also the sampling interval of the time and allocation profile.
-         The default is 0.02&nbsp;second.</para>
+         The default is 0.02&nbsp;seconds.</para>
        </listitem>
      </varlistentry>
 
@@ -501,13 +562,14 @@
           <indexterm><primary><option>-xc</option></primary><secondary>RTS option</secondary></indexterm>
         </term>
 	<listitem>
-	  <para>This option makes use of the extra information
-	  maintained by the cost-centre-stack profiler to provide
-	  useful information about the location of runtime errors.
-	  See <xref linkend="rts-options-debugging"/>.</para>
-	</listitem>
+          <para>This option causes the runtime to print out the
+          current cost-centre stack whenever an exception is raised.
+          This can be particularly useful for debugging the location
+          of exceptions, such as the notorious <literal>Prelude.head:
+          empty list</literal> error.  See <xref
+          linkend="rts-options-debugging"/>.</para>
+        </listitem>
       </varlistentry>
-
     </variablelist>
 
   </sect1>
@@ -520,7 +582,7 @@
     over time.  This is useful for detecting the causes of
     <firstterm>space leaks</firstterm>, when your program holds on to
     more memory at run-time that it needs to.  Space leaks lead to
-    longer run-times due to heavy garbage collector activity, and may
+    slower execution due to heavy garbage collector activity, and may
     even cause the program to run out of memory altogether.</para>
 
     <para>To generate a heap profile from your program:</para>
@@ -532,7 +594,7 @@
       </listitem>
       <listitem>
 	<para>Run it with one of the heap profiling options described
-	below (eg. <option>-hc</option> for a basic producer profile).
+        below (eg. <option>-h</option> for a basic producer profile).
 	This generates the file
 	<filename><replaceable>prog</replaceable>.hp</filename>.</para>
       </listitem>
@@ -550,6 +612,16 @@
       </listitem>
     </orderedlist>
 
+    <para>For example, here is a heap profile produced for the program given above in <xref linkend="scc-pragma" />:</para>
+
+      <!--
+           contentwidth/contentheight don't appear to have any effect
+           other than making the PS file generation work, rather than
+           falling over.  The result seems to be broken PS on the page
+           with the image. -->
+      <imagedata fileref="prof_scc" contentwidth="645px"
+      contentdepth="428px"/>
+
     <para>You might also want to take a look
       at <ulink url="http://www.haskell.org/haskellwiki/Hp2any">hp2any</ulink>,
       a more advanced suite of tools (not distributed with GHC) for
@@ -571,7 +643,7 @@
             <indexterm><primary><option>-hc</option></primary><secondary>RTS option</secondary></indexterm>
           </term>
 	  <listitem>
-	    <para>Breaks down the graph by the cost-centre stack which
+            <para>(can be shortened to <option>-h</option>). Breaks down the graph by the cost-centre stack which
 	    produced the data.</para>
 	  </listitem>
 	</varlistentry>
@@ -782,8 +854,9 @@
 	    space the program is using.</para>
 
 	    <para>Memory occupied by threads and their stacks is
-	    labelled as &ldquo;TSO&rdquo; when displaying the profile
-	    by closure description or type description.</para>
+	    labelled as &ldquo;TSO&rdquo; and &ldquo;STACK&rdquo;
+	    respectively when displaying the profile by closure
+	    description or type description.</para>
 	  </listitem>
 	</varlistentry>
 
@@ -1298,6 +1371,44 @@
 </sect2>
   </sect1>
 
+  <sect1 id="prof-threaded">
+    <title>Profiling Parallel and Concurrent Programs</title>
+
+    <para>Combining <option>-threaded</option>
+      and <option>-prof</option> is perfectly fine, and indeed it is
+      possible to profile a program running on multiple processors
+      with the <option>+RTS -N</option> option.<footnote>This feature
+      was added in GHC 7.4.1.</footnote>
+    </para>
+
+    <para>
+      Some caveats apply, however.  In the current implementation, a
+      profiled program is likely to scale much less well than the
+      unprofiled program, because the profiling implementation uses
+      some shared data structures which require locking in the runtime
+      system.  Furthermore, the memory allocation statistics collected
+      by the profiled program are stored in shared memory
+      but <emphasis>not</emphasis> locked (for speed), which means
+      that these figures might be inaccurate for parallel programs.
+    </para>
+
+    <para>
+      We strongly recommend that you
+      use <option>-fno-prof-count-entries</option> when compiling a
+      program to be profiled on multiple cores, because the entry
+      counts are also stored in shared memory, and continuously
+      updating them on multiple cores is extremely slow.
+    </para>
+
+    <para>
+      We also recommend
+      using <ulink url="http://www.haskell.org/haskellwiki/ThreadScope">ThreadScope</ulink>
+      for profiling parallel programs; it offers a GUI for visualising
+      parallel execution, and is complementary to the time and space
+      profiling features provided with GHC.
+    </para>
+  </sect1>
+
   <sect1 id="hpc">
     <title>Observing Code Coverage</title>
     <indexterm><primary>code coverage</primary></indexterm>
@@ -1305,14 +1416,13 @@
     <indexterm><primary>hpc</primary></indexterm>
 
     <para>
-      Code coverage tools allow a programmer to determine what parts of
-      their code have been actually executed, and which parts have
+      Code coverage tools allow a programmer to determine what parts
+      of their code have been actually executed, and which parts have
       never actually been invoked.  GHC has an option for generating
       instrumented code that records code coverage as part of the
-      <ulink url="http://www.haskell.org/hpc">Haskell Program Coverage
-      </ulink>(HPC) toolkit, which is included with GHC. HPC tools can
-      be used to render the generated code coverage information into
-      human understandable format.  </para>
+      Haskell Program Coverage (HPC) toolkit, which is included with
+      GHC. HPC tools can be used to render the generated code coverage
+      information into human understandable format.  </para>
 
     <para>
       Correctly instrumented code provides coverage information of two
@@ -1327,8 +1437,8 @@
 
     <para>
       HPC displays both kinds of information in two primary ways:
-      textual reports with summary statistics (hpc report) and sources
-      with color mark-up (hpc markup).  For boolean coverage, there
+      textual reports with summary statistics (<literal>hpc report</literal>) and sources
+      with color mark-up (<literal>hpc markup</literal>).  For boolean coverage, there
       are four possible outcomes for each guard, condition or
       qualifier: both True and False values occur; only True; only
       False; never evaluated. In hpc-markup output, highlighting with
@@ -1340,7 +1450,7 @@
    <sect2><title>A small example: Reciprocation</title>
 
     <para>
-     For an example we have a program, called Recip.hs, which computes exact decimal
+     For an example we have a program, called <filename>Recip.hs</filename>, which computes exact decimal
      representations of reciprocals, with recurring parts indicated in
      brackets.
     </para>
@@ -1377,21 +1487,35 @@
   main
 </programlisting>
 
-    <para>The HPC instrumentation is enabled using the -fhpc flag.
+    <para>HPC instrumentation is enabled with the -fhpc flag:
     </para>
 
 <screen>
-$ ghc -fhpc Recip.hs --make
+$ ghc -fhpc Recip.hs
 </screen>
-    <para>HPC index (.mix) files are placed in .hpc subdirectory. These can be considered like
-    the .hi files for HPC.
-   </para>
+    <para>GHC creates a subdirectory <filename>.hpc</filename> in the
+    current directory, and puts HPC index (<filename>.mix</filename>)
+    files in there, one for each module compiled.  You don't need to
+    worry about these files: they contain information needed by the
+    <literal>hpc</literal> tool to generate the coverage data for
+    compiled modules after the program is run.</para>
 <screen>
 $ ./Recip
 1/3
 = 0.(3)
 </screen>
-    <para>We can generate a textual summary of coverage:</para>
+    <para>Running the program generates a file with the
+    <literal>.tix</literal> suffix, in this case
+    <filename>Recip.tix</filename>, which contains the coverage data
+    for this run of the program.  The program may be run multiple
+    times (e.g. with different test data), and the coverage data from
+    the separate runs is accumulated in the <filename>.tix</filename>
+    file.  To reset the coverage data and start again, just remove the
+    <filename>.tix</filename> file.
+    </para>
+
+    <para>Having run the program, we can generate a textual summary of
+    coverage:</para>
 <screen>
 $ hpc report Recip
  80% expressions used (81/101)
@@ -1418,20 +1542,32 @@
      </sect2>
 
      <sect2><title>Options for instrumenting code for coverage</title>
-	<para>
-		Turning on code coverage is easy, use the -fhpc flag.
-		Instrumented and non-instrumented can be freely mixed.
-		When compiling the Main module GHC automatically detects when there
-		is an hpc compiled file, and adds the correct initialization code.
-	</para>
+
+     <variablelist>
+       <varlistentry>
+         <term><option>-fhpc</option></term>
+         <indexterm><primary><option>-fhpc</option></primary></indexterm>
+        <listitem>
+          <para>Enable code coverage for the current module or modules
+          being compiled.</para>
+
+          <para>Modules compiled with this option can be freely mixed
+          with modules compiled without it; indeed, most libraries
+          will typically be compiled without <option>-fhpc</option>.
+          When the program is run, coverage data will only be
+          generated for those modules that were compiled with
+          <option>-fhpc</option>, and the <literal>hpc</literal> tool
+          will only show information about those modules.
+          </para>
+	</listitem>
+      </varlistentry>
+     </variablelist>
 
      </sect2>
 
      <sect2><title>The hpc toolkit</title>
 
-      <para>
-      The hpc toolkit uses a cvs/svn/darcs-like interface, where a
-      single binary contains many function units.</para>
+      <para>The hpc command has several sub-commands:</para>
 <screen>
 $ hpc
 Usage: hpc COMMAND ...
@@ -1453,18 +1589,17 @@
   version     Display version for hpc
 </screen>
 
-     <para>In general, these options act on .tix file after an
-     instrumented binary has generated it, which hpc acting as a
-     conduit between the raw .tix file, and the more detailed reports
-     produced.
+     <para>In general, these options act on a
+     <filename>.tix</filename> file after an instrumented binary has
+     generated it.
 	</para>
 
 	<para>
 		The hpc tool assumes you are in the top-level directory of
-		the location where you built your application, and the .tix
+                the location where you built your application, and the <filename>.tix</filename>
 		file is in the same top-level directory. You can use the
-		flag --srcdir to use hpc for any other directory, and use
-		--srcdir multiple times to analyse programs compiled from
+                flag <option>--srcdir</option> to use <literal>hpc</literal> for any other directory, and use
+                <option>--srcdir</option> multiple times to analyse programs compiled from
 		difference locations, as is typical for packages.
 	</para>
 
@@ -1473,10 +1608,10 @@
      </para>
 
        <sect3><title>hpc report</title>
-		<para>hpc report gives a textual report of coverage. By default,
+                <para><literal>hpc report</literal> gives a textual report of coverage. By default,
 			all modules and packages are considered in generating report,
 			unless include or exclude are used. The report is a summary
-			unless the --per-module flag is used. The --xml-output option
+                        unless the <option>--per-module</option> flag is used. The <option>--xml-output</option> option
 			allows for tools to use hpc to glean coverage.
 		</para>
 <screen>
@@ -1497,7 +1632,7 @@
 </screen>
        </sect3>
        <sect3><title>hpc markup</title>
-		<para>hpc markup marks up source files into colored html.
+                <para><literal>hpc markup</literal> marks up source files into colored html.
 		</para>
 <screen>
 $ hpc help markup
@@ -1518,8 +1653,8 @@
 
        </sect3>
        <sect3><title>hpc sum</title>
-		<para>hpc sum adds together any number of .tix files into a single
-		.tix file. hpc sum does not change the original .tix file; it generates a new .tix file.
+                <para><literal>hpc sum</literal> adds together any number of <filename>.tix</filename> files into a single
+                <filename>.tix</filename> file. <literal>hpc sum</literal> does not change the original <filename>.tix</filename> file; it generates a new <filename>.tix</filename> file.
 		</para>
 <screen>
 $ hpc help sum
@@ -1535,10 +1670,10 @@
 </screen>
        </sect3>
        <sect3><title>hpc combine</title>
-		<para>hpc combine is the swiss army knife of hpc. It can be
-		 used to take the difference between .tix files, to subtract one
-		.tix file from another, or to add two .tix files. hpc combine does not
-		change the original .tix file; it generates a new .tix file.
+                <para><literal>hpc combine</literal> is the swiss army knife of <literal>hpc</literal>. It can be
+                 used to take the difference between <filename>.tix</filename> files, to subtract one
+		<filename>.tix</filename> file from another, or to add two <filename>.tix</filename> files. hpc combine does not
+		change the original <filename>.tix</filename> file; it generates a new <filename>.tix</filename> file.
 		</para>
 <screen>
 $ hpc help combine
@@ -1556,8 +1691,8 @@
 </screen>
        </sect3>
        <sect3><title>hpc map</title>
-		<para>hpc map inverts or zeros a .tix file. hpc map does not
-		change the original .tix file; it generates a new .tix file.
+		<para>hpc map inverts or zeros a <filename>.tix</filename> file. hpc map does not
+		change the original <filename>.tix</filename> file; it generates a new <filename>.tix</filename> file.
 		</para>
 <screen>
 $ hpc help map
@@ -1608,9 +1743,9 @@
      </sect2>
      <sect2><title>Caveats and Shortcomings of Haskell Program Coverage</title>
 	  <para>
-		HPC does not attempt to lock the .tix file, so multiple concurrently running
+		HPC does not attempt to lock the <filename>.tix</filename> file, so multiple concurrently running
 		binaries in the same directory will exhibit a race condition. There is no way
-		to change the name of the .tix file generated, apart from renaming the binary.
+		to change the name of the <filename>.tix</filename> file generated, apart from renaming the binary.
 		HPC does not work with GHCi.
   	  </para>
     </sect2>
diff -urd 7.2.2-original/runghc.xml original/runghc.xml
--- 7.2.2-original/runghc.xml	2011-11-10 02:10:39.000000000 +0800
+++ original/runghc.xml	2012-02-02 02:10:32.000000000 +0800
@@ -26,8 +26,8 @@
     <literal>[program args]</literal> and
     <literal>module</literal> are, but you can use a
     <literal>--</literal> flag if it doesn't get it right. For example,
-    <literal>runghc -- -fglasgow-exts Foo</literal> means runghc
-    won't try to use <literal>glasgow-exts</literal> as the path to GHC,
+    <literal>runghc -- -fwarn-unused-bindings Foo</literal> means runghc
+    won't try to use <literal>warn-unused-bindings</literal> as the path to GHC,
     but instead will pass the flag to GHC. If a GHC flag doesn't start
     with a dash then you need to prefix it with
     <literal>--ghc-arg=</literal> or runghc will think that it is the
diff -urd 7.2.2-original/runtime_control.xml original/runtime_control.xml
--- 7.2.2-original/runtime_control.xml	2011-11-10 02:10:39.000000000 +0800
+++ original/runtime_control.xml	2012-02-02 02:10:32.000000000 +0800
@@ -135,8 +135,10 @@
         <para>
           GHC lets you change the default RTS options for a program at
           compile time, using the <literal>-with-rtsopts</literal>
-          flag (<xref linkend="options-linker" />). For example, to
-          set <literal>-H128m -K64m</literal>, link
+          flag (<xref linkend="options-linker" />).  A common use for this is
+          to give your program a default heap and/or stack size that is
+          greater than the default.  For example, to set <literal>-H128m
+            -K64m</literal>, link
           with <literal>-with-rtsopts="-H128m -K64m"</literal>.
         </para>
       </sect3>
@@ -187,37 +189,17 @@
     <indexterm><primary>RTS hooks</primary></indexterm>
     <indexterm><primary>RTS behaviour, changing</primary></indexterm>
 
-    <para>GHC lets you exercise rudimentary control over the RTS
+    <para>GHC lets you exercise rudimentary control over certain RTS
     settings for any given program, by compiling in a
     &ldquo;hook&rdquo; that is called by the run-time system.  The RTS
-    contains stub definitions for all these hooks, but by writing your
+    contains stub definitions for these hooks, but by writing your
     own version and linking it on the GHC command line, you can
     override the defaults.</para>
 
     <para>Owing to the vagaries of DLL linking, these hooks don't work
     under Windows when the program is built dynamically.</para>
 
-    <para>The hook <literal>ghc_rts_opts</literal><indexterm><primary><literal>ghc_rts_opts</literal></primary>
-      </indexterm>lets you set RTS
-    options permanently for a given program, in the same way as the
-    newer <option>-with-rtsopts</option> linker option does.  A common use for this is
-    to give your program a default heap and/or stack size that is
-    greater than the default.  For example, to set <literal>-H128m
-    -K1m</literal>, place the following definition in a C source
-    file:</para>
-
-<programlisting>
-char *ghc_rts_opts = "-H128m -K1m";
-</programlisting>
-
-    <para>Compile the C file, and include the object file on the
-    command line when you link your Haskell program.</para>
-
-    <para>These flags are interpreted first, before any RTS flags from
-    the <literal>GHCRTS</literal> environment variable and any flags
-    on the command line.</para>
-
-    <para>You can also change the messages printed when the runtime
+    <para>You can change the messages printed when the runtime
     system &ldquo;blows up,&rdquo; e.g., on stack overflow.  The hooks
     for these are as follows:</para>
 
@@ -254,11 +236,6 @@
 	</listitem>
       </varlistentry>
     </variablelist>
-
-    <para>For examples of the use of these hooks, see GHC's own
-    versions in the file
-    <filename>ghc/compiler/parser/hschooks.c</filename> in a GHC
-    source tree.</para>
   </sect3>
 
     </sect2>
@@ -543,26 +520,34 @@
 
       <varlistentry>
 	<term>
-          <option>-H</option><replaceable>size</replaceable>
+          <option>-H</option><optional><replaceable>size</replaceable></optional>
           <indexterm><primary><option>-H</option></primary><secondary>RTS option</secondary></indexterm>
           <indexterm><primary>heap size, suggested</primary></indexterm>
         </term>
 	<listitem>
 	  <para>&lsqb;Default: 0&rsqb; This option provides a
-          &ldquo;suggested heap size&rdquo; for the garbage collector.  The
-          garbage collector will use about this much memory until the
-          program residency grows and the heap size needs to be
-          expanded to retain reasonable performance.</para>
+            &ldquo;suggested heap size&rdquo; for the garbage
+            collector.  Think
+            of <option>-H<replaceable>size</replaceable></option> as a
+            variable <option>-A</option> option.  It says: I want to
+            use at least <replaceable>size</replaceable> bytes, so use
+            whatever is left over to increase the <option>-A</option>
+            value.</para>
 
-	  <para>By default, the heap will start small, and grow and
-          shrink as necessary.  This can be bad for performance, so if
-          you have plenty of memory it's worthwhile supplying a big
-          <option>-H</option><replaceable>size</replaceable>.  For
-          improving GC performance, using
-          <option>-H</option><replaceable>size</replaceable> is
-          usually a better bet than
-          <option>-A</option><replaceable>size</replaceable>.</para>
-	</listitem>
+          <para>This option does not put
+            a <emphasis>limit</emphasis> on the heap size: the heap
+            may grow beyond the given size as usual.</para>
+
+          <para>If <replaceable>size</replaceable> is omitted, then
+            the garbage collector will take the size of the heap at
+            the previous GC as the <replaceable>size</replaceable>.
+            This has the effect of allowing for a
+            larger <option>-A</option> value but without increasing
+            the overall memory requirements of the program.  It can be
+            useful when the default small <option>-A</option> value is
+            suboptimal, as it can be in programs that create large
+            amounts of long-lived data.</para>
+        </listitem>
       </varlistentry>
 
       <varlistentry>
@@ -745,6 +730,10 @@
 
       <varlistentry>
         <term>
+          <option>-T</option>
+          <indexterm><primary><option>-T</option></primary><secondary>RTS option</secondary></indexterm>
+        </term>
+        <term>
           <option>-t</option><optional><replaceable>file</replaceable></optional>
           <indexterm><primary><option>-t</option></primary><secondary>RTS option</secondary></indexterm>
         </term>
@@ -766,6 +755,7 @@
 	  garbage collector, the amount of memory allocated, the
 	  maximum size of the heap, and so on.  The three
 	  variants give different levels of detail:
+          <option>-T</option> collects the data but produces no output
 	  <option>-t</option> produces a single line of output in the
 	  same format as GHC's <option>-Rghc-timing</option> option,
 	  <option>-s</option> produces a more detailed summary at the
@@ -779,6 +769,12 @@
           is sent to <constant>stderr</constant>.</para>
 
     <para>
+        If you use the <literal>-T</literal> flag then, you should
+        access the statistics using
+        <ulink url="&libraryBaseLocation;/GHC-Stats.html">GHC.Stats</ulink>.
+    </para>
+
+    <para>
         If you use the <literal>-t</literal> flag then, when your
         program finishes, you will see something like this:
     </para>
@@ -1060,7 +1056,7 @@
               option</secondary></indexterm>
         </term>
         <listitem>
-          <para>Generates a basic heap profile, in the
+          <para>(can be shortened to <option>-h</option>.) Generates a basic heap profile, in the
             file <literal><replaceable>prog</replaceable>.hp</literal>.
             To produce the heap profile graph,
             use <command>hp2ps</command> (see <xref linkend="hp2ps"
@@ -1093,7 +1089,7 @@
         <para>
           In binary format to a file for later analysis by a
           variety of tools.  One such tool
-          is <ulink url="http://hackage.haskell.org/package/ThreadScope">ThreadScope</ulink><indexterm><primary>ThreadScope</primary></indexterm>,
+          is <ulink url="http://www.haskell.org/haskellwiki/ThreadScope">ThreadScope</ulink><indexterm><primary>ThreadScope</primary></indexterm>,
           which interprets the event log to produce a visual parallel
           execution profile of the program.
         </para>
@@ -1114,11 +1110,60 @@
         <listitem>
           <para>
             Log events in binary format to the
-            file <filename><replaceable>program</replaceable>.eventlog</filename>,
-            where <replaceable>flags</replaceable> is a sequence of
-            zero or more characters indicating which kinds of events
-            to log.  Currently there is only one type
-            supported: <literal>-ls</literal>, for scheduler events.
+            file <filename><replaceable>program</replaceable>.eventlog</filename>.
+            Without any <replaceable>flags</replaceable> specified, this logs a
+            default set of events, suitable for use with tools like ThreadScope.
+          </para>
+
+          <para>
+            For some special use cases you may want more control over which
+            events are included. The <replaceable>flags</replaceable> is a
+            sequence of zero or more characters indicating which classes of
+            events to log. Currently there are four classes of events that can
+            be enabled/disabled:
+            <simplelist>
+              <member>
+                <option>s</option> &#8212; scheduler events, including Haskell
+                thread creation and start/stop events
+              </member>
+              <member>
+                <option>g</option> &#8212; GC events, including GC start/stop
+              </member>
+              <member>
+                <option>p</option> &#8212; parallel sparks (sampled)
+              </member>
+              <member>
+                <option>f</option> &#8212; parallel sparks (fully accurate)
+              </member>
+            </simplelist>
+          </para>
+
+          <para>            
+            For spark events there are two modes: sampled and fully accurate.
+            There are various events in the life cycle of each spark, usually
+            just creating and running, but there are some more exceptional
+            possibilities. In the sampled mode the number of occurrences of each
+            kind of spark event is sampled at frequent intervals. In the fully
+            accurate mode every spark event is logged individually. The latter
+            has a higher runtime overhead and is not enabled by default.
+          </para>
+
+          <para>            
+            The initial enabled event classes are 's', 'g' and 'p'. In addition
+            you can disable specific classes, or enable/disable all classes at
+            once:
+            <simplelist>
+              <member>
+                <option>a</option> &#8212; enable all event classes listed above
+              </member>
+              <member>
+                <option>-<replaceable>x</replaceable></option> &#8212; disable the
+                given class of events, for any event class listed above or
+                <option>-a</option> for all classes
+              </member>
+            </simplelist>
+            For example, <option>-l-ag</option> would disable all event classes
+            (<option>-a</option>) except for GC events (<option>g</option>).
           </para>
 
           <para>
@@ -1128,7 +1173,7 @@
             the <ulink url="http://hackage.haskell.org/package/ghc-events">ghc-events</ulink>
             library.  To dump the contents of
             a <literal>.eventlog</literal> file as text, use the
-            tool <literal>show-ghc-events</literal> that comes with
+            tool <literal>ghc-events-show</literal> that comes with
             the <ulink url="http://hackage.haskell.org/package/ghc-events">ghc-events</ulink>
             package.
           </para>
@@ -1256,34 +1301,60 @@
 	<listitem>
 	  <para>(Only available when the program is compiled for
 	  profiling.)  When an exception is raised in the program,
-	  this option causes the current cost-centre-stack to be
-	  dumped to <literal>stderr</literal>.</para>
+          this option causes a stack trace to be
+          dumped to <literal>stderr</literal>.</para>
 
 	  <para>This can be particularly useful for debugging: if your
 	  program is complaining about a <literal>head []</literal>
 	  error and you haven't got a clue which bit of code is
 	  causing it, compiling with <literal>-prof
-	  -auto-all</literal> and running with <literal>+RTS -xc
+          -fprof-auto</literal> and running with <literal>+RTS -xc
 	  -RTS</literal> will tell you exactly the call stack at the
 	  point the error was raised.</para>
 
-	  <para>The output contains one line for each exception raised
-	  in the program (the program might raise and catch several
-	  exceptions during its execution), where each line is of the
-	  form:</para>
+          <para>The output contains one report for each exception
+          raised in the program (the program might raise and catch
+          several exceptions during its execution), where each report
+          looks something like this:
+          </para>
 
 <screen>
-&lt; cc<subscript>1</subscript>, ..., cc<subscript>n</subscript> &gt;
+*** Exception raised (reporting due to +RTS -xc), stack trace:
+  GHC.List.CAF
+  --> evaluated by: Main.polynomial.table_search,
+  called from Main.polynomial.theta_index,
+  called from Main.polynomial,
+  called from Main.zonal_pressure,
+  called from Main.make_pressure.p,
+  called from Main.make_pressure,
+  called from Main.compute_initial_state.p,
+  called from Main.compute_initial_state,
+  called from Main.CAF
+  ...
 </screen>
-	  <para>each <literal>cc</literal><subscript>i</subscript> is
-	  a cost centre in the program (see <xref
-	  linkend="cost-centres"/>), and the sequence represents the
-	  &ldquo;call stack&rdquo; at the point the exception was
-	  raised.  The leftmost item is the innermost function in the
-	  call stack, and the rightmost item is the outermost
-	  function.</para>
+          <para>The stack trace may often begin with something
+          uninformative like <literal>GHC.List.CAF</literal>; this is
+          an artifact of GHC's optimiser, which lifts out exceptions
+          to the top-level where the profiling system assigns them to
+          the cost centre "CAF".  However, <literal>+RTS -xc</literal>
+          doesn't just print the current stack, it looks deeper and
+          reports the stack at the time the CAF was evaluated, and it
+          may report further stacks until a non-CAF stack is found.  In
+          the example above, the next stack (after <literal>-->
+          evaluated by</literal>) contains plenty of information about
+          what the program was doing when it evaluated <literal>head
+          []</literal>.</para>
 
-	</listitem>
+          <para>Implementation details aside, the function names in
+          the stack should hopefully give you enough clues to track
+          down the bug.</para>
+
+          <para>
+            See also the function <literal>traceStack</literal> in the
+            module <literal>Debug.Trace</literal> for another way to
+            view call stacks.
+          </para>
+        </listitem>
       </varlistentry>
 
       <varlistentry>
@@ -1303,7 +1374,7 @@
 
   </sect2>
 
-  <sect2>
+  <sect2 id="ghc-info">
     <title>Getting information about the RTS</title>
 
     <indexterm><primary>RTS</primary></indexterm>
@@ -1423,7 +1494,8 @@
       <varlistentry>
         <term><literal>Compiler unregistered</literal></term>
         <listitem>
-          <para>Was this program compiled with an &ldquo;unregistered&rdquo;
+          <para>Was this program compiled with an
+          <link linkend="unreg">&ldquo;unregistered&rdquo;</link>
           version of GHC? (I.e., a version of GHC that has no platform-specific
           optimisations compiled in, usually because this is a currently
           unsupported platform.) This value will usually be no, unless you're
diff -urd 7.2.2-original/safe_haskell.xml original/safe_haskell.xml
--- 7.2.2-original/safe_haskell.xml	2011-11-10 02:10:39.000000000 +0800
+++ original/safe_haskell.xml	2012-02-02 02:10:32.000000000 +0800
@@ -1,18 +1,32 @@
 <?xml version="1.0" encoding="iso-8859-1"?>
 <sect1 id="safe-haskell">
   <title>Safe Haskell</title>
+  <indexterm><primary>safe haskell</primary></indexterm>
 
   <para>
   Safe Haskell is an extension to the Haskell language that is implemented in
   GHC as of version 7.2. It allows for unsafe code to be securely included in a
   trusted code base by restricting the features of GHC Haskell the code is
-  allowed to use. Put simply, it makes the types of programs trustable.  Safe
-  Haskell itself is aimed to be as minimal as possible while still providing
-  strong enough guarantees about compiled Haskell code for more advance secure
-  systems to be built on top of it. These include techniques such as
-  information flow control security or encrypted computations.
+  allowed to use. Put simply, it makes the types of programs trustable. Safe
+  Haskell is aimed to be as minimal as possible while still providing strong
+  enough guarantees about compiled Haskell code for more advance secure systems
+  to be built on top of it.
   </para>
 
+  <para>
+  While this is the use case that Safe Haskell was motivated by it is important
+  to understand that what Safe Haskell is tracking and enforcing is a stricter
+  form of type safety than is usually guaranteed in Haskell. As part of this,
+  Safe Haskell is run during every compilation of GHC, tracking safety and
+  inferring it even for modules that don't explicitly use Safe Haskell. Please
+  refer to section <xref linkend="safe-inference"/> for more details of this.
+  This also means that there are some design choices that from a security point
+  of view may seem strange but when thought of from the angle of tracking type
+  safety are logical. Feedback on the current design and this tension between
+  the security and type safety view points is welcome.
+  </para>
+
+  <para>
   The design of Safe Haskell covers the following aspects:
 
   <itemizedlist>
@@ -20,24 +34,28 @@
       Haskell that provides guarantees about the code. It allows types and
       module boundaries to be trusted.
     </listitem>
-    <listitem>A new <emphasis>safe import</emphasis> extension that specifies
-      that the module being imported must be trusted.
+    <listitem>A <emphasis>safe import</emphasis> extension that specifies that
+      the module being imported must be trusted.
     </listitem>
     <listitem>A definition of <emphasis>trust</emphasis> (or safety) and how it
       operates, along with ways of defining and changing the trust of modules
       and packages.
     </listitem>
   </itemizedlist>
+  </para>
 
   <sect2 id="safe-use-cases">
     <title>Uses of Safe Haskell</title>
+    <indexterm><primary>safe haskell uses</primary></indexterm>
 
+    <para>
     Safe Haskell has been designed with two use cases in mind:
 
     <itemizedlist>
       <listitem>Enforcing strict type safety at compile time</listitem>
       <listitem>Compiling and executing untrusted code</listitem>
     </itemizedlist>
+    </para>
 
     <sect3>
       <title>Strict type-safety (good style)</title>
@@ -51,22 +69,24 @@
       Haskell code easier to analyze and reason about. It also codifies an
       existing culture in the Haskell community of trying to avoid using such
       unsafe functions unless absolutely necessary. As such using the safe
-      language (through the <option>-XSafe</option> flag) can be thought of as a
-      way of enforcing good style, similar to the function of
+      language (through the <option>-XSafe</option> flag) can be thought of as
+      a way of enforcing good style, similar to the function of
       <option>-Wall</option>.
     </sect3>
 
     <sect3>
       <title>Building secure systems (restricted IO Monads)</title>
+      <indexterm><primary>secure haskell</primary></indexterm>
 
       <para>
-      Safe Haskell is designed to give users enough guarantees about the safety
-      properties of compiled code so that secure systems can be built using
-      Haskell. A lot of work has been done with Haskell, building such systems
-      as information flow control security, capability based security, DSLs for
-      working with encrypted data... etc. These systems all rely on properties
-      of the Haskell language that aren't true in the general case where uses
-      of functions like <literal>unsafePerformIO</literal> are allowed.
+      Systems such as information flow control security, capability based
+      security systems and DSLs for working with encrypted data.. etc can be
+      built in the Haskell language simply as a library. However they require
+      guarantees about the properties of the Haskell language that aren't true
+      in the general case where uses of functions like <literal>unsafePerformIO
+      </literal> are allowed. Safe Haskell is designed to give users enough
+      guarantees about the safety properties of compiled code so that such
+      secure systems can be built.
       </para>
 
       <para>
@@ -120,8 +140,10 @@
         runMe = ...
       </programlisting>
 
+      <para>
       Before going into the Safe Haskell details, lets point out some of
       the reasons this design would fail without Safe Haskell:
+      </para>
 
       <itemizedlist>
         <listitem>The design attempts to restrict the operations that Danger
@@ -161,7 +183,7 @@
       FFI functions, Generalized Newtype Deriving, RULES and restricting the
       operation of Overlapping Instances. The <option>-XSafe</option> flag also
       restricts the modules can be imported by Danger to only those that are
-      considered trusted.  Trusted modules are those compiled with
+      considered trusted. Trusted modules are those compiled with
       <option>-XSafe</option>, where GHC provides a mechanical guarantee that
       the code is safe. Or those modules compiled with
       <option>-XTrustworthy</option>, where the module author claims that the
@@ -174,10 +196,14 @@
       The <option>-XTrustworthy</option> flag doesn't place any restrictions on
       the module like <option>-XSafe</option> does. Instead the module author
       claims that while code may use unsafe features internally, it only
-      exposes an API that can used in a safe manner. There is an issue here as
-      <option>-XTrustworthy</option> may be used by an arbitrary module and
-      module author. Because of this for trustworthy modules to be considered
-      trusted, and so allowed to be used in <option>-XSafe</option> compiled
+      exposes an API that can used in a safe manner. The use of
+      <option>-XTrustworthy</option> by itself marks the module as trusted.
+      There is an issue here as <option>-XTrustworthy</option> may be used by
+      an arbitrary module and module author. To control the use of trustworthy
+      modules it is recommended to use the <option>-fpackage-trust</option>
+      flag. This flag adds an extra requirement to the trust check for
+      trustworthy modules, such that for trustworthy modules to be considered
+      trusted, and allowed to be used in <option>-XSafe</option> compiled
       code, the client C compiling the code must tell GHC that they trust the
       package the trustworthy module resides in. This is essentially a way of
       for C to say, while this package contains trustworthy modules that can be
@@ -185,23 +211,25 @@
       the author(s) of this package and trust the modules only expose a safe
       API. The trust of a package can be changed at any time, so if a
       vulnerability found in a package, C can declare that package untrusted so
-      that any future compilation against that package would fail.  For a more
+      that any future compilation against that package would fail. For a more
       detailed overview of this mechanism see <xref linkend="safe-trust"/>.
       </para>
 
       <para>
-      So Danger can import module RIO because RIO is marked trustworthy. Thus,
-      Danger can make use of the rioReadFile and rioWriteFile functions to
-      access permitted file names. The main application then imports both RIO
-      and Danger. To run the plugin, it calls RIO.runRIO Danger.runMe within
-      the IO monad. The application is safe in the knowledge that the only IO
-      to ensue will be to files whose paths were approved by the pathOK test.
+      In the example, Danger can import module RIO because RIO is marked
+      trustworthy. Thus, Danger can make use of the rioReadFile and
+      rioWriteFile functions to access permitted file names. The main
+      application then imports both RIO and Danger. To run the plugin, it calls
+      RIO.runRIO Danger.runMe within the IO monad. The application is safe in
+      the knowledge that the only IO to ensue will be to files whose paths were
+      approved by the pathOK test.
       </para>
     </sect3>
   </sect2>
 
   <sect2 id="safe-language">
     <title>Safe Language</title>
+    <indexterm><primary>safe language</primary></indexterm>
 
     The Safe Haskell <emphasis>safe language</emphasis> guarantees the
     following properties:
@@ -227,7 +255,7 @@
         Because of this, <emphasis><link linkend="template-haskell">Template
         Haskell</link></emphasis> and <emphasis>
         <link linkend="newtype-deriving">GeneralizedNewtypeDeriving</link>
-        </emphasis> are both disabled in the safe language as they can be used
+        </emphasis> are disabled in the safe language as they can be used
         to violate this property.
       </listitem>
       <listitem><emphasis>Semantic consistency</emphasis> &mdash; The safe
@@ -245,10 +273,10 @@
     </itemizedlist>
 
     <para>
-    These three properties guarantee that you can trust the types in the safe
-    language, can trust that module export lists are respected in the safe
-    language and can trust that code that successfully compiles using the safe
-    language has the same meaning as it normally would.
+    These three properties guarantee that in the safe language you can trust
+    the types, can trust that module export lists are respected and can trust
+    that code that successfully compiles has the same meaning as it normally
+    would.
     </para>
 
     Lets now look at the details of the safe language. In the safe language
@@ -259,12 +287,10 @@
       <listitem><emphasis>GeneralizedNewtypeDeriving</emphasis> &mdash; It can
         be used to violate constructor access control, by allowing untrusted
         code to manipulate protected data types in ways the data type author
-        did not intend. For example can be used to break invariants of data
-        structures.</listitem>
+        did not intend, breaking invariants they have established.</listitem>
       <listitem><emphasis>TemplateHaskell</emphasis> &mdash; Is particularly
         dangerous, as it can cause side effects even at compilation time and
-        can be used to access abstract data types. It is very easy to break
-        module boundaries with TH.</listitem>
+        can be used to access constructors of abstract data types.</listitem>
    </itemizedlist>
 
     In the safe language dialect we restrict the following features:
@@ -275,7 +301,7 @@
         IO Monad.</listitem>
       <listitem><emphasis>RULES</emphasis> &mdash; As they can change the
         behaviour of trusted code in unanticipated ways, violating semantic
-        consistency they are restricted in function. Specifically any RULES
+        consistency, they are restricted in function. Specifically any RULES
         defined in a module M compiled with <option>-XSafe</option> are
         dropped. RULES defined in trustworthy modules that M imports are still
         valid and will fire as usual.</listitem>
@@ -293,17 +319,18 @@
         compilation error will occur. A simple way to think of this is a
         <emphasis>same origin policy</emphasis> for overlapping instances
         defined in Safe compiled modules.</listitem>
-	  <listitem><emphasis>Data.Typeable</emphasis> &mdash; We restrict Typeable
-		  instances to only derived ones (offered by GHC through the 
-		  <link linkend="deriving-typeable"><option>-XDeriveDataTypeable</option>
-		  </link> extension). Hand crafted instances of the Typeable type class
-		  are not allowed in Safe Haskell as this can easily be abused to 
-		  unsafely coerce between types.</listitem>
+     <listitem><emphasis>Data.Typeable</emphasis> &mdash; We restrict Typeable
+        instances to only derived ones (offered by GHC through the 
+        <link linkend="deriving-typeable"><option>-XDeriveDataTypeable</option>
+        </link> extension). Hand crafted instances of the Typeable type class
+        are not allowed in Safe Haskell as this can easily be abused to 
+        unsafely coerce between types.</listitem>
     </itemizedlist>
   </sect2>
 
   <sect2 id="safe-imports">
     <title>Safe Imports</title>
+    <indexterm><primary>safe imports</primary></indexterm>
 
     Safe Haskell enables a small extension to the usual import syntax of
     Haskell, adding a <emphasis>safe</emphasis> keyword:
@@ -314,16 +341,18 @@
     When used, the module being imported with the safe keyword must be a
     trusted module, otherwise a compilation error will occur. The safe import
     extension is enabled by either of the <option>-XSafe</option>,
-    <option>-XTrustworthy</option>, or <option>-XSafeImports</option>
+    <option>-XTrustworthy</option>, or <option>-XUnsafe</option>
     flags and corresponding PRAGMA's. When the <option>-XSafe</option> flag
     is used, the safe keyword is allowed but meaningless, every import
     is required to be safe regardless.
   </sect2>
 
   <sect2 id="safe-trust">
-    <title>Trust</title>
+    <title>Trust and Safe Haskell Modes</title>
+    <indexterm><primary>safe haskell trust</primary></indexterm>
+    <indexterm><primary>trust</primary></indexterm>
 
-    The Safe Haskell extension introduces the following two new language flags:
+    The Safe Haskell extension introduces the following three language flags:
 
     <itemizedlist>
       <listitem><emphasis>-XSafe</emphasis> &mdash; Enables the safe language
@@ -331,55 +360,149 @@
         requires that all imports be trusted or a compilation error will
         occur.</listitem>
       <listitem><emphasis>-XTrustworthy</emphasis> &mdash; Means that while
-        this module may invoke unsafe functions internally, the module's
-        author claims that it exports an API that can't be used in an unsafe
-        way.  This doesn't enable the safe language or place any restrictions
-        on the allowed Haskell code.  The trust guarantee is provided by the
-        module author, not GHC. An import statement with the safe keyword
-        results in a compilation error if the imported module is not trusted.
-        An import statement without the keyword behaves as usual and can
-        import any module whether trusted or not.</listitem>
+        this module may invoke unsafe functions internally, the module's author
+        claims that it exports an API that can't be used in an unsafe way. This
+        doesn't enable the safe language or place any restrictions on the
+        allowed Haskell code. The trust guarantee is provided by the module
+        author, not GHC. An import statement with the safe keyword results in a
+        compilation error if the imported module is not trusted.  An import
+        statement without the keyword behaves as usual and can import any
+        module whether trusted or not.</listitem>
+      <listitem><emphasis>-XUnsafe</emphasis> &mdash; Marks the module being
+        compiled as unsafe so that modules compiled using
+        <option>-XSafe</option> can't import it.
+      </listitem>
     </itemizedlist>
 
     <para>
-    Whether or not a module is trusted depends on a notion of trust for
-    packages, which is determined by the client C invoking GHC (i.e. you). A
-    package <emphasis>P</emphasis> is trusted when either C's package database
-    records that <emphasis>P</emphasis> is trusted (and no command-line
-    arguments override this), or C's command-line flags say to trust it
-    regardless of what is recorded in the package database. In either case, C
-    is the only authority on package trust. It is up to the client to decide
-    which <link linkend="safe-package-trust">packages they trust</link>.
+    The procedure to check if a module is trusted or not depends on if the
+    <option>-fpackage-trust</option> flag is present. The check is very similar
+    in both cases with the presence of the <option>-fpackage-trust</option>
+    flag simply enabling an extra requirement for trustworthy modules to be
+    regarded as trusted.
     </para>
 
-    So a <emphasis>module M in a package P is trusted by a client C</emphasis>
-    if and only if:
+    <sect3>
+      <title>Trust check (<option>-fpackage-trust</option> disabled)</title>
+      <indexterm><primary>trust check</primary></indexterm>
 
-    <itemizedlist>
-      <listitem>Both of these hold:
-        <itemizedlist>
-          <listitem> The module was compiled with <option>-XSafe</option>
-            </listitem>
-          <listitem> All of M's direct imports are trusted by C</listitem>
-        </itemizedlist>
-      </listitem>
-      <listitem><emphasis>OR</emphasis> all of these hold:
-        <itemizedlist>
-          <listitem>The module was compiled with <option>-XTrustworthy</option>
-            </listitem>
-          <listitem>All of M's direct safe imports are trusted by C</listitem>
-          <listitem>Package P is trusted by C</listitem>
-        </itemizedlist>
-      </listitem>
-    </itemizedlist>
+      <para>
+      A <emphasis>module M in a package P is trusted by a client C</emphasis>
+      if and only if:
 
-    For the first trust definition the trust guarantee is provided by GHC
-    through the restrictions imposed by the safe language. For the second
-    definition of trust, the guarantee is provided initially by the
-    module author. The client C then establishes that they trust the
-    module author by indicating they trust the package the module resides
-    in. This trust chain is required as GHC provides no guarantee for
-    <literal>-XTrustworthy</literal> compiled modules.
+      <itemizedlist>
+        <listitem>Both of these hold:
+          <itemizedlist>
+            <listitem>The module was compiled with <option>-XSafe</option>
+              </listitem>
+            <listitem>All of M's direct imports are trusted by C</listitem>
+          </itemizedlist>
+        </listitem>
+        <listitem><emphasis>OR</emphasis> all of these hold:
+          <itemizedlist>
+            <listitem>The module was compiled with
+              <option>-XTrustworthy</option></listitem>
+            <listitem>All of M's direct safe imports are trusted by C</listitem>
+          </itemizedlist>
+        </listitem>
+      </itemizedlist>
+      </para>
+
+      <para>
+      The above definition of trust has an issue. Any module can be compiled
+      with -XTrustworthy and it will be trusted regardless of what it does. To
+      control this there is an additional definition of package trust (enabled
+      with the <option>-fpackage-trust</option> flag). The point of package
+      trusts is to require that the client C explicitly say which packages are
+      allowed to contain trustworthy modules. That is, C establishes that it
+      trusts a package P and its author and so trust the modules in P that use
+      <option>-XTrustworthy</option>. When package trust is enabled, any
+      modules that are considered trustworthy but reside in a package that
+      isn't trusted are not considered trusted. A more formal definition is
+      given in the next section.
+      </para>
+    </sect3>
+
+    <sect3>
+      <title>Trust check (<option>-fpackage-trust</option> enabled)</title>
+      <indexterm><primary>trust check</primary></indexterm>
+      <indexterm><primary>-fpackage-trust</primary></indexterm>
+
+      <para>
+      When the <option>-fpackage-trust</option> flag is enabled, whether or not
+      a module is trusted depends on a notion of trust for packages, which is
+      determined by the client C invoking GHC (i.e. you). A package <emphasis>P
+      is trusted</emphasis> when one of these hold:
+      <itemizedlist>
+        <listitem>C's package database records that P is trusted (and no
+          command-line arguments override this)</listitem>
+        <listitem>C's command-line flags say to trust P regardless of what is
+          recorded in the package database.</listitem>
+      </itemizedlist>
+      </para>
+
+      <para>
+      In either case, C is the only authority on package trust. It is up to the
+      client to decide which <link linkend="safe-package-trust">packages they
+      trust</link>.
+      </para>
+
+      <para>
+      When the <option>-fpackage-trust</option> flag is used a <emphasis>module M from
+      package P is trusted by a client C</emphasis> if and only if:
+
+      <itemizedlist>
+        <listitem>Both of these hold:
+          <itemizedlist>
+            <listitem> The module was compiled with <option>-XSafe</option>
+              </listitem>
+            <listitem> All of M's direct imports are trusted by C</listitem>
+          </itemizedlist>
+        </listitem>
+        <listitem><emphasis>OR</emphasis> all of these hold:
+          <itemizedlist>
+            <listitem>The module was compiled with
+              <option>-XTrustworthy</option></listitem>
+            <listitem>All of M's direct safe imports are trusted by C</listitem>
+            <listitem>Package P is trusted by C</listitem>
+          </itemizedlist>
+        </listitem>
+      </itemizedlist>
+      </para>
+
+      <para>
+      For the first trust definition the trust guarantee is provided by GHC
+      through the restrictions imposed by the safe language. For the second
+      definition of trust, the guarantee is provided initially by the
+      module author. The client C then establishes that they trust the
+      module author by indicating they trust the package the module resides
+      in. This trust chain is required as GHC provides no guarantee for
+      <literal>-XTrustworthy</literal> compiled modules.
+      </para>
+
+      <para>
+      The reason there are two modes of checking trust is that the extra
+      requirement enabled by <option>-fpackage-trust</option> causes the design
+      of Safe Haskell to be invasive. Packages using Safe Haskell when the flag
+      is enabled may or may not compile depending on the state of trusted
+      packages on a users machine. A maintainer of a package
+      <literal>foo</literal> that uses Safe Haskell so that security conscious
+      Haskellers can use <literal>foo</literal> now may have other users of
+      <literal>foo</literal> who don't know or care about Safe Haskell
+      complaining about compilation problems they are having with
+      <literal>foo</literal>because a package <literal>bar</literal>that foo
+      requires, isn't trusted on their machine. In this sense, the
+      <option>-fpackage-trust</option> flag can be thought of as a flag to
+      properly turn on Safe Haskell while without it, it's operating in a
+      covert fashion.
+      </para>
+
+      <para>
+      Having the <option>-fpackage-trust</option> flag also nicely unifies the
+      semantics of how Safe Haskell works when used explicitly and how modules
+      are <ulink linkend="safe-inference">inferred as safe</ulink>.
+      </para>
+    </sect3>
 
     <sect3 id="safe-trust-example">
       <title>Example</title>
@@ -422,8 +545,20 @@
       </para>
     </sect3>
 
+    <sect3 id="trustworthy-guarantees">
+      <title>Trustworthy Requirements</title>
+      <indexterm><primary>trustworthy</primary></indexterm>
+
+      Module authors using the <option>-XTrustworthy</option> language
+      extension for a module M should ensure that M's public API (the symbols
+      exposed by its export list) can't be used in an unsafe manner.  This mean
+      that symbols exported should respect type safety and referential
+      transparency.
+    </sect3>
+
     <sect3 id="safe-package-trust">
       <title>Package Trust</title>
+      <indexterm><primary>package trust</primary></indexterm>
 
       Safe Haskell gives packages a new Boolean property, that of trust.
       Several new options are available at the GHC command-line to specify the
@@ -445,35 +580,57 @@
       <xref linkend="packages"/>.
     </sect3>
 
-    <sect3 id="safe-no-trust">
-      <title>Safe Imports without Trust</title>
+  </sect2>
 
-      If you are writing a module and want to import a module from an untrusted
-      author, then you would use the following syntax:
+  <sect2 id="safe-inference">
+    <title>Safe Haskell Inference</title>
+    <indexterm><primary>safe inference</primary></indexterm>
 
-      <programlisting>
-        import safe Untrusted.Module
-      </programlisting>
+    <para>
+    In the case where a module is compiled without one of
+    <option>-XSafe</option>, <option>-XTrustworthy</option> or
+    <option>-XUnsafe</option> being used, GHC will try to figure out itself if
+    the module can be considered safe. This safety inference will never mark a
+    module as trustworthy, only as either unsafe or as safe. GHC uses a simple
+    method to determine this for a module M: If M would compile without error
+    under the <option>-XSafe</option> flag, then M is marked as safe. If M
+    would fail to compile under the <option>-XSafe</option> flag, then it is
+    marked as unsafe. 
+    </para>
 
-      As the safe import keyword is a feature of Safe Haskell and not Haskell98
-      this would fail though unless you enabled Safe imports through on the of
-      the Safe Haskell language flags. Three flags enable safe imports,
-      <option>-XSafe, -XTrustworthy</option> and
-      <option>-XSafeImports</option>. However <option>-XSafe</option> and
-      <option>-XTrustworthy</option> do more then just enable the keyword which
-      may be undesirable. Using the <option>-XSafeImports</option> language
-      flag allows you to enable safe imports and nothing more.
-    </sect3>
+    <para>
+    When should you use Safe Haskell inference and when should you use an
+    explicit <option>-XSafe</option> flag? The later case should be used when
+    you have a hard requirement that the module be safe. That is, the
+    <ulink linkend="safe-use-cases">use cases</ulink> outlined and the purpose
+    for which Safe Haskell is intended: compiling untrusted code. Safe
+    inference is meant to be used by ordinary Haskell programmers. Users who
+    probably don't care about Safe Haskell. 
+    </para>
+
+    <para>
+    Say you are writing a Haskell library. Then you probably just want to use
+    Safe inference. Assuming you avoid any unsafe features of the language then
+    your modules will be marked safe. This is a benefit as now a user of your
+    library who may want to use it as part of an API exposed to untrusted code
+    can use the library without change. If there wasn't safety inference then
+    either the writer of the library would have to explicitly use Safe Haskell,
+    which is an unreasonable expectation of the whole Haskell community. Or the
+    user of the library would have to wrap it in a shim that simply re-exported
+    your API through a trustworthy module, an annoying practice.
+    </para>
   </sect2>
 
   <sect2 id="safe-flag-summary">
     <title>Safe Haskell Flag Summary</title>
+    <indexterm><primary>safe haskell flags</primary></indexterm>
 
-    In summary, Safe Haskell consists of the following language flags:
+    In summary, Safe Haskell consists of the following three language flags:
 
     <variablelist>
       <varlistentry>
         <term>-XSafe</term>
+        <indexterm><primary>-XSafe</primary></indexterm>
         <listitem>To be trusted, all of the module's direct imports must be
           trusted, but the module itself need not reside in a trusted
           package, because the compiler vouches for its trustworthiness. The
@@ -491,6 +648,7 @@
 
       <varlistentry>
         <term>-XTrustworthy</term>
+        <indexterm><primary>-XTrustworthy</primary></indexterm>
         <listitem>This establishes that the module is trusted, but the
           guarantee is provided by the module's author. A client of this
           module then specifies that they trust the module author by
@@ -499,8 +657,10 @@
           of Haskell programs or their semantics, except that they allow the
           safe import keyword.
           <itemizedlist>
-            <listitem><emphasis>Module Trusted</emphasis> &mdash; Yes but only if the
-              package the module resides in is also trusted.</listitem>
+            <listitem><emphasis>Module Trusted</emphasis> &mdash; Yes.</listitem>
+            <listitem><emphasis>Module Trusted (<option>-fpackage-trust</option>
+              enabled)</emphasis> &mdash; Yes but only if the package the module
+              resides in is also trusted.</listitem>
             <listitem><emphasis>Haskell Language</emphasis> &mdash; Unrestricted
             </listitem>
             <listitem><emphasis>Imported Modules</emphasis> &mdash; Under control of
@@ -510,10 +670,11 @@
       </varlistentry>
 
       <varlistentry>
-        <term>-XSafeImport</term>
-        <listitem>Enable the Safe Import extension so that a module can
-          require a dependency to be trusted without asserting any trust
-          about itself.
+        <term>-XUnsafe</term>
+        <indexterm><primary>-XUnsafe</primary></indexterm>
+        <listitem>Mark a module as unsafe so that it can't be imported by code
+          compiled with <option>-XSafe</option>. Also enable the Safe Import
+          extension so that a module can require a dependency to be trusted.
           <itemizedlist>
             <listitem><emphasis>Module Trusted</emphasis> &mdash; No</listitem>
             <listitem><emphasis>Haskell Language</emphasis> &mdash;
@@ -526,6 +687,39 @@
 
     </variablelist>
 
+    And one general flag:
+
+    <variablelist>
+      <varlistentry>
+        <term>-fpackage-trust</term>
+        <indexterm><primary>-fpackage-trust</primary></indexterm>
+        <listitem>When enabled turn on an extra check for a trustworthy module
+          M, requiring that the package M resides in is considered trusted for
+          the M to be considered trusted.
+        </listitem>
+      </varlistentry>
+    </variablelist>
+
+    And two warning flags:
+
+    <variablelist>
+      <varlistentry>
+        <term>-fwarn-unsafe</term>
+        <indexterm><primary>-fwarn-unsafe</primary></indexterm>
+        <listitem>Issue a warning if the module being compiled is regarded
+          to be unsafe. Should be used to check the safety status of modules
+          when using safe inference.
+        </listitem>
+      </varlistentry>
+      <varlistentry>
+        <term>-fwarn-safe</term>
+        <indexterm><primary>-fwarn-safe</primary></indexterm>
+        <listitem>Issue a warning if the module being compiled is regarded
+          to be safe. Should be used to check the safety status of modules
+          when using safe inference.
+        </listitem>
+      </varlistentry>
+    </variablelist>
   </sect2>
 
 </sect1>
diff -urd 7.2.2-original/separate_compilation.xml original/separate_compilation.xml
--- 7.2.2-original/separate_compilation.xml	2011-11-10 02:10:39.000000000 +0800
+++ original/separate_compilation.xml	2012-02-02 02:10:32.000000000 +0800
@@ -374,6 +374,19 @@
 	  </listitem>
 	</varlistentry>
 
+	<varlistentry>
+	  <term>
+            <option>-dumpdir</option>  <replaceable>dir</replaceable>
+            <indexterm><primary><option>-dumpdir</option></primary></indexterm>
+          </term>
+	  <listitem>
+	    <para>Redirects all dump files into
+	    <replaceable>dir</replaceable>.  Dump files are generated when
+	    <literal>-ddump-to-file</literal> is used with other
+	    <literal>-ddump-*</literal> flags.</para>
+	  </listitem>
+	</varlistentry>
+
         <varlistentry>
           <term>
             <option>-outputdir</option> <replaceable>dir</replaceable>
@@ -383,7 +396,7 @@
             <para>The <option>-outputdir</option> option is shorthand for
               the combination
               of <option>-odir</option>, <option>-hidir</option>,
-              and <option>-stubdir</option>.
+              <option>-stubdir</option> and <option>-dumpdir</option>.
             </para>
           </listitem>
         </varlistentry>
@@ -460,8 +473,9 @@
 	  <listitem>
 	    <para>Keep intermediate <literal>.hc</literal> files when
 	    doing <literal>.hs</literal>-to-<literal>.o</literal>
-	    compilations via C (NOTE: <literal>.hc</literal> files
-	    are only generated by unregisterised compilers).</para>
+      compilations via <link linkend="c-code-gen">C</link> (NOTE:
+      <literal>.hc</literal> files are only generated by
+      <link linkend="unreg">unregisterised</link> compilers).</para>
 	  </listitem>
 	</varlistentry>
 
@@ -475,10 +489,10 @@
 	  <listitem>
 	    <para>Keep intermediate <literal>.ll</literal> files when
 	    doing <literal>.hs</literal>-to-<literal>.o</literal>
-	    compilations via LLVM (NOTE: <literal>.ll</literal> files
-	    aren't generated when using the native code generator, you
-	    may need to use <option>-fllvm</option> to force them
-	    to be produced).</para>
+      compilations via <link linkend="llvm-code-gen">LLVM</link>
+      (NOTE: <literal>.ll</literal> files aren't generated when using the
+      native code generator, you may need to use <option>-fllvm</option> to
+      force them to be produced).</para>
 	  </listitem>
 	</varlistentry>
 
diff -urd 7.2.2-original/sooner.xml original/sooner.xml
--- 7.2.2-original/sooner.xml	2011-11-10 02:10:39.000000000 +0800
+++ original/sooner.xml	2012-02-02 02:10:32.000000000 +0800
@@ -154,11 +154,15 @@
       <varlistentry>
 	<term>Compile via LLVM:</term>
 	<listitem>
-		<para>The LLVM code generator can sometimes do a far better job
-			    at producing fast code then either the native code generator
-					or the C code generator. This is not universal and depends
-					on the code. Numeric heavy code seems to show the best
-					improvement when compiled via LLVM.</para>
+		<para>The <link linkend="llvm-code-gen">LLVM code generator</link> can
+			sometimes do a far better job at producing fast code than the <link
+				linkend="native-code-gen">native code generator</link>. This is not
+			universal and depends on the code. Numeric heavy code seems to show
+			the best improvement when compiled via LLVM. You can also experiment
+			with passing specific flags to LLVM with the <option>-optlo</option>
+			and <option>-optlc</option> flags.  Be careful though as setting these
+			flags stops GHC from setting its usual flags for the LLVM optimiser
+			and compiler.</para>
 	</listitem>
       </varlistentry>
 
diff -urd 7.2.2-original/ug-book.xml original/ug-book.xml
--- 7.2.2-original/ug-book.xml	2011-11-29 17:45:28.000000000 +0800
+++ original/ug-book.xml	2012-02-03 18:09:44.000000000 +0800
@@ -1,6 +1,6 @@
 <?xml version="1.0" encoding="iso-8859-1"?>
 <bookinfo>
-<title>The Glorious Glasgow Haskell Compilation System User's Guide, Version 7.2.2</title>
+<title>The Glorious Glasgow Haskell Compilation System User's Guide, Version 7.4.1</title>
 <author><othername>The GHC Team</othername></author>
 <address>
 <email>glasgow-haskell-&lcub;bugs,users&rcub;-request@haskell.org</email>
diff -urd 7.2.2-original/ug-ent.xml original/ug-ent.xml
--- 7.2.2-original/ug-ent.xml	2011-11-29 17:45:28.000000000 +0800
+++ original/ug-ent.xml	2012-02-03 18:09:44.000000000 +0800
@@ -25,6 +27,6 @@
 <!ENTITY ffi-chap       SYSTEM "ffi-chap.xml">
 <!ENTITY shared_libs    SYSTEM "shared_libs.xml">
 <!ENTITY what_glasgow_exts_does SYSTEM "what_glasgow_exts_does.gen.xml">
-<!ENTITY libraryBaseLocation    "../libraries/base-4.4.1.0">
-<!ENTITY libraryCabalLocation   "../libraries/Cabal-1.12.0">
+<!ENTITY libraryBaseLocation    "../libraries/base-4.5.0.0">
+<!ENTITY libraryCabalLocation   "../libraries/Cabal-1.14.0">
 <!ENTITY libraryGhcPrimLocation "../libraries/ghc-prim-0.2.0.0">
diff -urd 7.2.2-original/ug-ent.xml.in original/ug-ent.xml.in
--- 7.2.2-original/ug-ent.xml.in	2011-11-10 02:10:39.000000000 +0800
+++ original/ug-ent.xml.in	2012-02-02 02:10:32.000000000 +0800
@@ -3,9 +3,11 @@
 <!ENTITY flags          SYSTEM "flags.xml">
 <!ENTITY license        SYSTEM "license.xml">
 <!ENTITY intro          SYSTEM "intro.xml" >
-<!ENTITY relnotes1      SYSTEM "7.2.1-notes.xml" >
-<!ENTITY relnotes2      SYSTEM "7.2.2-notes.xml" >
+<!ENTITY oldrelnotes1   SYSTEM "7.2.1-notes.xml" >
+<!ENTITY oldrelnotes2   SYSTEM "7.2.2-notes.xml" >
+<!ENTITY relnotes1      SYSTEM "7.4.1-notes.xml" >
 <!ENTITY using          SYSTEM "using.xml" >
+<!ENTITY code-gens      SYSTEM "codegens.xml" >
 <!ENTITY runtime        SYSTEM "runtime_control.xml" >
 <!ENTITY prof           SYSTEM "profiling.xml" >
 <!ENTITY debug          SYSTEM "debugging.xml" >
diff -urd 7.2.2-original/using.xml original/using.xml
--- 7.2.2-original/using.xml	2011-11-10 02:10:39.000000000 +0800
+++ original/using.xml	2012-02-02 02:10:32.000000000 +0800
@@ -731,11 +731,9 @@
       <filename>Foo.hs</filename> to an object file
       <filename>Foo.o</filename>.</para>
 
-      <para>Note: What the Haskell compiler proper produces depends on
-      whether a native-code generator<indexterm><primary>native-code
-      generator</primary></indexterm> is used (producing assembly
-      language) or not (producing C).  See <xref
-      linkend="options-codegen"/> for more details.</para>
+      <para>Note: What the Haskell compiler proper produces depends on what
+      backend code generator is used. See <xref linkend="code-generators"/>
+      for more details.</para>
 
       <para>Note: C pre-processing is optional, the
       <option>-cpp</option><indexterm><primary><option>-cpp</option></primary></indexterm>
@@ -1755,6 +1753,28 @@
 
 	<varlistentry>
 	  <term>
+            <option>-fignore-interface-pragmas</option>
+	    <indexterm><primary><option>-fignore-interface-pragmas</option></primary></indexterm>
+          </term>
+	  <listitem>
+	    <para>Tells GHC to ignore all inessential information when reading interface files.
+	    That is, even if <filename>M.hi</filename> contains unfolding or strictness information
+	    for a function, GHC will ignore that information.</para>
+	  </listitem>
+	</varlistentry>
+
+	<varlistentry>
+	  <term>
+            <option>-fliberate-case</option>
+            <indexterm><primary><option>-fliberate-case</option></primary></indexterm>
+          </term>
+	  <listitem>
+	    <para>Turn on the liberate-case transformation.</para>
+	  </listitem>
+	</varlistentry>
+
+	<varlistentry>
+	  <term>
             <option>-fno-cse</option>
             <indexterm><primary><option>-fno-cse</option></primary></indexterm>
           </term>
@@ -1820,75 +1840,89 @@
 
 	<varlistentry>
 	  <term>
-            <option>-fspec-constr</option>
-            <indexterm><primary><option>-fspec-constr</option></primary></indexterm>
+            <option>-fno-state-hack</option>
+            <indexterm><primary><option>-fno-state-hack</option></primary></indexterm>
           </term>
 	  <listitem>
-	    <para>Turn on call-pattern specialisation.</para>
+	    <para>Turn off the "state hack" whereby any lambda with a
+	      <literal>State#</literal> token as argument is considered to be
+	      single-entry, hence it is considered OK to inline things inside
+	      it.  This can improve performance of IO and ST monad code, but it
+	    runs the risk of reducing sharing.</para>
 	  </listitem>
 	</varlistentry>
 
 	<varlistentry>
 	  <term>
-            <option>-fliberate-case</option>
-            <indexterm><primary><option>-fliberate-case</option></primary></indexterm>
+            <option>-fpedantic-bottoms</option>
+            <indexterm><primary><option>-fpedantic-bottoms</option></primary></indexterm>
           </term>
 	  <listitem>
-	    <para>Turn on the liberate-case transformation.</para>
+	    <para>Make GHC be more precise about its treatment of bottom (but see also
+                     <option>-fno-state-hack</option>). In particular, stop GHC 
+                     eta-expanding through a case expression, which is good for
+		     performance, but bad if you are using <literal>seq</literal> on
+                     partial applications.</para>
 	  </listitem>
 	</varlistentry>
 
 	<varlistentry>
 	  <term>
-            <option>-fstatic-argument-transformation</option>
-            <indexterm><primary><option>-fstatic-argument-transformation</option></primary></indexterm>
+            <option>-fomit-interface-pragmas</option>
+	    <indexterm><primary><option>-fomit-interface-pragmas</option></primary></indexterm>
           </term>
 	  <listitem>
-	    <para>Turn on the static argument transformation.</para>
+	    <para>Tells GHC to omit all inessential information from the interface file
+	      generated for the module being compiled (say M).  This means that a module
+	      importing M will see only the <emphasis>types</emphasis> of the functions that M exports, but not
+	      their unfoldings, strictness info, etc.  Hence, for example,
+	      no function exported by M will be inlined
+	      into an importing module.  The benefit is that modules that import M will
+	      need to be recompiled less often (only when M's exports change their type,
+	      not when they change their implementation).
+	      </para>
 	  </listitem>
 	</varlistentry>
 
 	<varlistentry>
 	  <term>
-            <option>-fno-state-hack</option>
-            <indexterm><primary><option>-fno-state-hack</option></primary></indexterm>
+            <option>-fsimpl-tick-factor=<replaceable>n</replaceable></option>
+            <indexterm><primary><option>-fsimpl-tick-factor</option></primary></indexterm>
           </term>
 	  <listitem>
-	    <para>Turn off the "state hack" whereby any lambda with a
-	      <literal>State#</literal> token as argument is considered to be
-	      single-entry, hence it is considered OK to inline things inside
-	      it.  This can improve performance of IO and ST monad code, but it
-	    runs the risk of reducing sharing.</para>
+	    <para>GHC's optimiser can diverge if you write rewrite rules (<xref linkend="rewrite-rules"/>) 
+              that don't terminate, or (less satisfactorily) if you
+              code up recursion through data types
+              (<xref linkend="bugs-ghc"/>).  To avoid making the compiler fall into an infinite
+	      loop, the optimiser carries a "tick count" and stops inlining and applying rewrite rules
+              when this count is exceeded.  The limit is set as a multiple of the program size, so 
+              bigger programs get more ticks. The <option>-fsimpl-tick-factor</option> flag lets
+              you change the multiplier. The default is 100; numbers larger than 100 give more ticks,
+              and numbers smaller than 100 give fewer.</para>
+            <para>If the tick-count expires, GHC summarises what simplifier steps it has done; 
+            you can use <option>-fddump-simpl-stats</option> to generate a much more detailed list.
+            Usually that identifies the loop quite accurately, because some numbers are very large.
+	      </para>
 	  </listitem>
 	</varlistentry>
 
 	<varlistentry>
 	  <term>
-            <option>-fomit-interface-pragmas</option>
-	    <indexterm><primary><option>-fomit-interface-pragmas</option></primary></indexterm>
+            <option>-fstatic-argument-transformation</option>
+            <indexterm><primary><option>-fstatic-argument-transformation</option></primary></indexterm>
           </term>
 	  <listitem>
-	    <para>Tells GHC to omit all inessential information from the interface file
-	      generated for the module being compiled (say M).  This means that a module
-	      importing M will see only the <emphasis>types</emphasis> of the functions that M exports, but not
-	      their unfoldings, strictness info, etc.  Hence, for example,
-	      no function exported by M will be inlined
-	      into an importing module.  The benefit is that modules that import M will
-	      need to be recompiled less often (only when M's exports change their type,
-	      not when they change their implementation).
-	      </para>
+	    <para>Turn on the static argument transformation.</para>
 	  </listitem>
 	</varlistentry>
 
 	<varlistentry>
 	  <term>
-            <option>-fignore-interface-pragmas</option>
-	    <indexterm><primary><option>-fignore-interface-pragmas</option></primary></indexterm>
+            <option>-fspec-constr</option>
+            <indexterm><primary><option>-fspec-constr</option></primary></indexterm>
           </term>
 	  <listitem>
-	    <para>Tells GHC to ignore all inessential information when reading interface files.
-	    That is, even if <filename>M.hi</filename> contains unfolding or strictness information
-	    for a function, GHC will ignore that information.</para>
+	    <para>Turn on call-pattern specialisation.</para>
 	  </listitem>
 	</varlistentry>
 
@@ -1910,7 +1944,12 @@
 	    <para>This option is a bit of a sledgehammer: it might
 	    sometimes make things worse.  Selectively unboxing fields
 	    by using <literal>UNPACK</literal> pragmas might be
-	    better.</para>
+	    better. An alternative is to use
+        <option>-funbox-strict-fields</option> to turn on
+        unboxing by default but disable it for certain constructor
+        fields using the <literal>NOUNPACK</literal> pragma
+        (see <xref linkend="nounpack-pragma"/>).
+        </para>
 	  </listitem>
 	</varlistentry>
 
@@ -1962,6 +2001,8 @@
 
   </sect1>
 
   &code-gens;
 
   &phases;
 
   &shared_libs;
@@ -2071,8 +2112,10 @@
     <sect2 id="parallel-options">
       <title>RTS options for SMP parallelism</title>
 
-      <para>To run a program on multiple CPUs, use the
-	RTS <option>-N</option> option:</para>
+      <para>There are two ways to run a program on multiple
+        processors:
+        call <literal>GHC.Conc.setNumCapabilities</literal> from your
+        program, or use the RTS <option>-N</option> option.</para>
 
       <variablelist>
 	<varlistentry>
@@ -2107,7 +2150,13 @@
 
             <para>The current value of the <option>-N</option> option
               is available to the Haskell program
-              via <literal>GHC.Conc.numCapabilities</literal>.</para>
+              via <literal>GHC.Conc.getNumCapabilities</literal>, and
+              it may be changed while the program is running by
+              calling <literal>GHC.Conc.setNumCapabilities</literal>.
+              Note: in the current implementation,
+              the <option>-N</option> value may only
+              be <emphasis>increased</emphasis>, not decreased, by
+              calling <literal>GHC.Conc.setNumCapabilities</literal>.</para>
 	  </listitem>
 	</varlistentry>
       </variablelist>
@@ -2191,19 +2240,38 @@
 	<term><option>-msse2</option>:</term>
 	<listitem>
           <para>
-            (x86 only, added in GHC 7.0.1) Use the SSE2 registers and
-            instruction set to implement floating point operations
-            when using the native code generator.  This gives a
-            substantial performance improvement for floating point,
-            but the resulting compiled code will only run on
-            processors that support SSE2 (Intel Pentium 4 and later,
-            or AMD Athlon 64 and later).
+				(x86 only, added in GHC 7.0.1) Use the SSE2 registers and
+				instruction set to implement floating point operations when using
+				the <link linkend="native-code-gen">native code generator</link>.
+				This gives a substantial performance improvement for floating
+				point, but the resulting compiled code
+				will only run on processors that support SSE2 (Intel Pentium 4 and
+				later, or AMD Athlon 64 and later). The
+				<link linkend="llvm-code-gen">LLVM backend</link> will also use SSE2
+				if your processor supports it but detects this automatically so no
+				flag is required.
           </para>
           <para>
             SSE2 is unconditionally used on x86-64 platforms.
           </para>
         </listitem>
       </varlistentry>
+
+      <varlistentry>
+	<term><option>-msse4.2</option>:</term>
+	<listitem>
+          <para>
+				(x86 only, added in GHC 7.4.1) Use the SSE4.2 instruction set to
+				implement some floating point and bit operations when using the
+				<link linkend="native-code-gen">native code generator</link>. The
+				resulting compiled code will only run on processors that
+				support SSE4.2 (Intel Core i7 and later). The
+				<link linkend="llvm-code-gen">LLVM backend</link> will also use
+				SSE4.2 if your processor supports it but detects this automatically
+				so no flag is required.
+          </para>
+        </listitem>
+      </varlistentry>
 
     </variablelist>
 
